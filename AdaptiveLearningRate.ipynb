{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AdaptiveLearningRate.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPXl/HQUYaoY1VLYatIPDuw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vigneshthanga/258-Deep-Learning/blob/master/AdaptiveLearningRate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuCKOzR2BHit",
        "colab_type": "text"
      },
      "source": [
        "##Magic lines to model reload"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqigdbMVpHy5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "#To reload all modules before executing a new line\n",
        "%reload_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XHDrMQsBLh6",
        "colab_type": "text"
      },
      "source": [
        "##Importing Tensorflow 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0MKHca8pL6J",
        "colab_type": "code",
        "outputId": "8b6962ba-a203-4feb-9962-0a62bc452071",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow\n",
        "print(tensorflow.__version__)\n",
        "from keras.datasets import mnist\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "2.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcK5Sfo7BPVC",
        "colab_type": "text"
      },
      "source": [
        "##Getting the data from Keras MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQSg2X6opQK-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "fa69cc29-ded3-4690-89a0-a40b8a01a2fa"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WS0ZwPmhBTJp",
        "colab_type": "text"
      },
      "source": [
        "##Reshaping the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uPLh1MftRnC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = np.float32(x_train[:])\n",
        "y_train = np.int32(np.array(y_train[:])).reshape(-1, 1)\n",
        "x_test  = np.float32(x_test[:])\n",
        "y_test  = np.int32(np.array(y_test[:])).reshape(-1, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-5FtgkmtUEL",
        "colab_type": "code",
        "outputId": "72cc61f0-7b6f-4b80-830f-7a702dfd65f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lk5fYtS4sn7V",
        "colab_type": "code",
        "outputId": "ae5655b4-f2e3-498f-ccbc-c12cda9ded7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "# stack together for next step\n",
        "X = np.vstack((x_train, x_test))\n",
        "y = np.vstack((y_train, y_test))\n",
        "\n",
        "print(X.shape)\n",
        "# one-hot encoding\n",
        "digits = 10\n",
        "examples = y.shape[0]\n",
        "y = y.reshape(1, examples)\n",
        "Y_new = np.eye(digits)[y.astype('int32')]\n",
        "Y_new = Y_new.T.reshape(digits, examples)\n",
        "\n",
        "\n",
        "# number of training set\n",
        "m = 60000\n",
        "m_test = X.shape[0] - m\n",
        "X_train, X_test = X[:m].T, X[m:].T\n",
        "Y_train, Y_test = Y_new[:, :m], Y_new[:, m:]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(70000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LD9VNaj2u1u0",
        "colab_type": "code",
        "outputId": "ac3cce4f-2d15-4560-ea0e-3f85054e8935",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Y_train.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 60000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnP2R3aV_zd5",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "##Defining model hyperparameters using Argparse\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BahtBYhusSlh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "\n",
        "parser.add_argument('--lr', type=float, default=0.25, help='learning rate')\n",
        "parser.add_argument('--epochs', type=int, default=100,\n",
        "                    help='number of epochs to train')\n",
        "parser.add_argument('--n_x', type=int, default=784, help='number of inputs')\n",
        "parser.add_argument('--n_h', type=int, default=784, help='number of hidden units')\n",
        "parser.add_argument('--beta', type=float, default=0.9,\n",
        "                    help='parameter for momentum')\n",
        "parser.add_argument('--batch_size', type=int,\n",
        "                    default=100, help='input batch size')\n",
        "\n",
        "opt, unknown = parser.parse_known_args()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_3Rm7obpU_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = {\"W1\": np.random.randn(opt.n_h, opt.n_x) * np.sqrt(1. / opt.n_x),\n",
        "          \"b1\": np.zeros((opt.n_h, 1)) * np.sqrt(1. / opt.n_x),\n",
        "          \"W2\": np.random.randn(digits, opt.n_h) * np.sqrt(1. / opt.n_h),\n",
        "          \"b2\": np.zeros((digits, 1)) * np.sqrt(1. / opt.n_h)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgVyAUj7BEl1",
        "colab_type": "text"
      },
      "source": [
        "##Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s76GpTZX4l5F",
        "colab_type": "code",
        "outputId": "4cf9ec09-03ab-496a-feb8-5a928a862f14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "params[\"W1\"]"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.0294798 , -0.00161355, -0.03193292, ..., -0.05675496,\n",
              "        -0.02373124, -0.02421886],\n",
              "       [ 0.00990358, -0.01155237, -0.00126738, ...,  0.02461497,\n",
              "         0.00641721,  0.02784202],\n",
              "       [ 0.00243215,  0.01341848,  0.01726891, ..., -0.00685754,\n",
              "         0.05479625, -0.04815378],\n",
              "       ...,\n",
              "       [ 0.00264246,  0.06827996, -0.02101158, ...,  0.09112652,\n",
              "         0.0211752 , -0.00939152],\n",
              "       [-0.00995382, -0.03183652, -0.00815587, ...,  0.02137897,\n",
              "         0.00063046, -0.03446351],\n",
              "       [ 0.024663  ,  0.0290985 , -0.04257172, ..., -0.06176446,\n",
              "        -0.03706899,  0.08575193]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVN4Zx9zA7HR",
        "colab_type": "text"
      },
      "source": [
        "##Sigmoid activation Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEgYB-ijpX2o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(z):\n",
        "    s = 1. / (1. + np.exp(-z))\n",
        "    return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpJYhmyCA-3f",
        "colab_type": "text"
      },
      "source": [
        "##Loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ompcTjEsF31",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_loss(Y, Y_hat):\n",
        "    L_sum = np.sum(np.multiply(Y, np.log(Y_hat)))\n",
        "    m = Y.shape[1]\n",
        "    L = -(1./m) * L_sum\n",
        "\n",
        "    return L\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-EEJmrsA3Dd",
        "colab_type": "text"
      },
      "source": [
        "##Forward Propogation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUrVlXDmsMD8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def feed_forward(X, params):\n",
        "    cache = {}\n",
        "\n",
        "    cache[\"Z1\"] = np.matmul(params[\"W1\"], X) + params[\"b1\"]\n",
        "\n",
        "    cache[\"A1\"] = sigmoid(cache[\"Z1\"])\n",
        "\n",
        "    cache[\"Z2\"] = np.matmul(params[\"W2\"], cache[\"A1\"]) + params[\"b2\"]\n",
        "\n",
        "    cache[\"A2\"] = np.exp(cache[\"Z2\"]) / np.sum(np.exp(cache[\"Z2\"]), axis=0)\n",
        "\n",
        "    return cache"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcrTDm09A0Yn",
        "colab_type": "text"
      },
      "source": [
        "##Back Propagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWLdw0e5sPgB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def back_propagate(X, Y, params, cache, m_batch):\n",
        "    dZ2 = cache[\"A2\"] - Y\n",
        "\n",
        "    dW2 = (1. / m_batch) * np.matmul(dZ2, cache[\"A1\"].T)\n",
        "    db2 = (1. / m_batch) * np.sum(dZ2, axis=1, keepdims=True)\n",
        "\n",
        "    dA1 = np.matmul(params[\"W2\"].T, dZ2)\n",
        "    dZ1 = dA1 * sigmoid(cache[\"Z1\"]) * (1 - sigmoid(cache[\"Z1\"]))\n",
        "\n",
        "    dW1 = (1. / m_batch) * np.matmul(dZ1, X.T)\n",
        "    db1 = (1. / m_batch) * np.sum(dZ1, axis=1, keepdims=True)\n",
        "\n",
        "    grads = {\"dW1\": dW1, \"db1\": db1, \"dW2\": dW2, \"db2\": db2}\n",
        "\n",
        "    return grads"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHDwaWlzBZo3",
        "colab_type": "text"
      },
      "source": [
        "##Reshaping the data for number of units in the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1cu_XQizDPC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(784, 60000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7oGY-474tjN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = X_test.reshape(784, 10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBPsnK-4YLDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batches = int(60000/opt.batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmsbJI2OYWoN",
        "colab_type": "code",
        "outputId": "9d26b5f3-fef3-4fd2-f9fd-17d1ae6d8a00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "batches"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "600"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hkcszB1ApEn",
        "colab_type": "text"
      },
      "source": [
        "##Initializing the weights adjustment for adaptive learning rate to zero."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqiJ45GF0Xby",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dW1 = 0.0\n",
        "db1 = 0.0\n",
        "dW2 = 0.0\n",
        "db2 = 0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKXVgAmnAl2g",
        "colab_type": "text"
      },
      "source": [
        "##Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyzPrPSOsWy6",
        "colab_type": "code",
        "outputId": "2e4dc015-4495-4b4a-a3bd-95867ffefbe2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(opt.epochs):\n",
        "\n",
        "    # shuffle training set\n",
        "    permutation = np.random.permutation(X_train.shape[1])\n",
        "    X_train_shuffled = X_train[:, permutation]\n",
        "    Y_train_shuffled = Y_train[:, permutation]\n",
        "\n",
        "    for j in range(batches):\n",
        "\n",
        "        # get mini-batch\n",
        "        begin = j * opt.batch_size\n",
        "        end = min(begin + opt.batch_size, X_train.shape[1] - 1)\n",
        "        X = X_train_shuffled[:, begin:end]\n",
        "        Y = Y_train_shuffled[:, begin:end]\n",
        "        m_batch = end - begin\n",
        "\n",
        "        # forward and backward\n",
        "        cache = feed_forward(X, params)\n",
        "        grads = back_propagate(X, Y, params, cache, m_batch)\n",
        "\n",
        "        # with momentum (optional)\n",
        "        dW1 = (opt.beta * dW1 + (1. - opt.beta) * grads[\"dW1\"])\n",
        "        db1 = (opt.beta * db1 + (1. - opt.beta) * grads[\"db1\"])\n",
        "        dW2 = (opt.beta * dW2 + (1. - opt.beta) * grads[\"dW2\"])\n",
        "        db2 = (opt.beta * db2 + (1. - opt.beta) * grads[\"db2\"])\n",
        "\n",
        "        # gradient descent\n",
        "        params[\"W1\"] = params[\"W1\"] - opt.lr * grads[\"dW1\"]\n",
        "        params[\"b1\"] = params[\"b1\"] - opt.lr * grads[\"db1\"]\n",
        "        params[\"W2\"] = params[\"W2\"] - opt.lr * grads[\"dW2\"]\n",
        "        params[\"b2\"] = params[\"b2\"] - opt.lr * grads[\"db2\"]\n",
        "\n",
        "    # forward pass on training set\n",
        "    #print(X_train.shape)\n",
        "    cache = feed_forward(X_train, params)\n",
        "    train_loss = compute_loss(Y_train, cache[\"A2\"])\n",
        "\n",
        "    # forward pass on test set\n",
        "    cache = feed_forward(X_test, params)\n",
        "    test_loss = compute_loss(Y_test, cache[\"A2\"])\n",
        "    print(\"Epoch {}: training loss = {}, test loss = {}\".format(\n",
        "        i + 1, train_loss, test_loss))\n"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: RuntimeWarning: overflow encountered in exp\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1: training loss = 0.6606738732421875, test loss = 0.6521100732622166\n",
            "Epoch 2: training loss = 0.5251529244516097, test loss = 0.4976227324384374\n",
            "Epoch 3: training loss = 1.3128759158967769, test loss = 1.3151056350428825\n",
            "Epoch 4: training loss = 0.6908824201741226, test loss = 0.6798823345824773\n",
            "Epoch 5: training loss = 0.6483697163155467, test loss = 0.6312633763675478\n",
            "Epoch 6: training loss = 0.772048716333725, test loss = 0.7788567492136141\n",
            "Epoch 7: training loss = 1.1041125122783837, test loss = 1.097442524248876\n",
            "Epoch 8: training loss = 1.5282761196889587, test loss = 1.5390180586197064\n",
            "Epoch 9: training loss = 0.7276709808010356, test loss = 0.7107148371475225\n",
            "Epoch 10: training loss = 0.5920808651427377, test loss = 0.5822078903466904\n",
            "Epoch 11: training loss = 0.7227974979482082, test loss = 0.7122925718687032\n",
            "Epoch 12: training loss = 0.47757543335911673, test loss = 0.4674146505852819\n",
            "Epoch 13: training loss = 0.5025260717205724, test loss = 0.4914527288997278\n",
            "Epoch 14: training loss = 0.47083571291298687, test loss = 0.4698629640233132\n",
            "Epoch 15: training loss = 0.5856039978017527, test loss = 0.5799118230572936\n",
            "Epoch 16: training loss = 0.4805148154426847, test loss = 0.4790874489728282\n",
            "Epoch 17: training loss = 0.38527440017884, test loss = 0.3724029246280181\n",
            "Epoch 18: training loss = 0.5704486677341231, test loss = 0.5561629743907749\n",
            "Epoch 19: training loss = 0.4579342753532071, test loss = 0.45877634552613594\n",
            "Epoch 20: training loss = 0.6072352255917343, test loss = 0.6288045681199816\n",
            "Epoch 21: training loss = 0.7540647600561262, test loss = 0.7432161402734714\n",
            "Epoch 22: training loss = 0.43082697149934485, test loss = 0.4223903188993561\n",
            "Epoch 23: training loss = 0.5777432826802433, test loss = 0.5967443907759262\n",
            "Epoch 24: training loss = 0.5891873006537139, test loss = 0.5889172441905643\n",
            "Epoch 25: training loss = 0.38972844094287956, test loss = 0.39290099647237575\n",
            "Epoch 26: training loss = 0.8222065759940502, test loss = 0.8386302386315616\n",
            "Epoch 27: training loss = 0.5581266808040086, test loss = 0.5666148674740205\n",
            "Epoch 28: training loss = 0.40243829258897884, test loss = 0.4033072861587309\n",
            "Epoch 29: training loss = 0.41560278600443784, test loss = 0.41917637706868804\n",
            "Epoch 30: training loss = 0.5804748633352146, test loss = 0.5704222251874786\n",
            "Epoch 31: training loss = 0.5661776791141214, test loss = 0.5741515391312547\n",
            "Epoch 32: training loss = 0.5031374047700495, test loss = 0.5022758129784319\n",
            "Epoch 33: training loss = 0.43664806559297087, test loss = 0.4368605816556373\n",
            "Epoch 34: training loss = 0.595836384513394, test loss = 0.6040088287759805\n",
            "Epoch 35: training loss = 0.4014429844053426, test loss = 0.41368915313518223\n",
            "Epoch 36: training loss = 0.6121485690947843, test loss = 0.6157643089502697\n",
            "Epoch 37: training loss = 0.49020355609586347, test loss = 0.5009843406612058\n",
            "Epoch 38: training loss = 0.5011124223169754, test loss = 0.4995201078345696\n",
            "Epoch 39: training loss = 0.4045522786175396, test loss = 0.40660198440666595\n",
            "Epoch 40: training loss = 0.42595116104165837, test loss = 0.41242972863433747\n",
            "Epoch 41: training loss = 0.3559786450080291, test loss = 0.35437325370552375\n",
            "Epoch 42: training loss = 0.583891087409615, test loss = 0.5752166379720091\n",
            "Epoch 43: training loss = 0.4442432217602766, test loss = 0.4515098282444611\n",
            "Epoch 44: training loss = 0.41591602100220704, test loss = 0.4188082127657297\n",
            "Epoch 45: training loss = 0.3901533107748514, test loss = 0.38740023915690813\n",
            "Epoch 46: training loss = 0.3809553198139085, test loss = 0.38352926544571775\n",
            "Epoch 47: training loss = 0.4360878560938751, test loss = 0.44723247584428966\n",
            "Epoch 48: training loss = 0.43243920629358273, test loss = 0.4309497608072551\n",
            "Epoch 49: training loss = 0.4689587058216739, test loss = 0.4679071752269886\n",
            "Epoch 50: training loss = 0.44387740060177217, test loss = 0.43635749081313707\n",
            "Epoch 51: training loss = 0.45254196915462513, test loss = 0.46336548751638423\n",
            "Epoch 52: training loss = 0.5431738994533727, test loss = 0.5530481097616792\n",
            "Epoch 53: training loss = 0.4067862754572577, test loss = 0.42190975129702085\n",
            "Epoch 54: training loss = 0.6817640963186646, test loss = 0.6739066278555098\n",
            "Epoch 55: training loss = 0.5221330817614614, test loss = 0.5246662851060397\n",
            "Epoch 56: training loss = 0.41702622735179184, test loss = 0.4237037257299524\n",
            "Epoch 57: training loss = 0.4411008929394055, test loss = 0.4297392318328254\n",
            "Epoch 58: training loss = 0.44953777765206915, test loss = 0.44121793192242614\n",
            "Epoch 59: training loss = 0.6081101045772838, test loss = 0.6289982136972858\n",
            "Epoch 60: training loss = 0.41024896934056276, test loss = 0.3981493702475533\n",
            "Epoch 61: training loss = 0.4032210754391375, test loss = 0.39413794802922525\n",
            "Epoch 62: training loss = 0.3992029293841717, test loss = 0.41336523701724576\n",
            "Epoch 63: training loss = 0.40333945560385376, test loss = 0.4141045743258214\n",
            "Epoch 64: training loss = 0.423717460855667, test loss = 0.4181498728356082\n",
            "Epoch 65: training loss = 0.3839208906418278, test loss = 0.3852343554252012\n",
            "Epoch 66: training loss = 0.3444906238000192, test loss = 0.35234854503805785\n",
            "Epoch 67: training loss = 0.4205572095129775, test loss = 0.438886243762467\n",
            "Epoch 68: training loss = 0.46636715381142935, test loss = 0.4741417713706856\n",
            "Epoch 69: training loss = 0.4166054804699107, test loss = 0.4208717909229091\n",
            "Epoch 70: training loss = 0.43218319208747286, test loss = 0.44389729531095556\n",
            "Epoch 71: training loss = 0.49759475409919085, test loss = 0.5075286154553771\n",
            "Epoch 72: training loss = 0.34030463959425983, test loss = 0.36338625917822776\n",
            "Epoch 73: training loss = 0.40585199024902113, test loss = 0.4276919353421704\n",
            "Epoch 74: training loss = 0.718508615724074, test loss = 0.7420163951334893\n",
            "Epoch 75: training loss = 0.4108543943643409, test loss = 0.42066459731888783\n",
            "Epoch 76: training loss = 0.45528019389739105, test loss = 0.4593371555976561\n",
            "Epoch 77: training loss = 0.39480570471887655, test loss = 0.4060812406283974\n",
            "Epoch 78: training loss = 0.3680733738270459, test loss = 0.3616039585534401\n",
            "Epoch 79: training loss = 0.46198073753400165, test loss = 0.4709700237970623\n",
            "Epoch 80: training loss = 0.42818818747464077, test loss = 0.4381257555251173\n",
            "Epoch 81: training loss = 0.39731639261133456, test loss = 0.4056041777716523\n",
            "Epoch 82: training loss = 0.3677745605794306, test loss = 0.3559446589897821\n",
            "Epoch 83: training loss = 0.39313272063552807, test loss = 0.38097640292282614\n",
            "Epoch 84: training loss = 0.5328732106532281, test loss = 0.5500832375512257\n",
            "Epoch 85: training loss = 0.7305863829804383, test loss = 0.7387460531819495\n",
            "Epoch 86: training loss = 1.2205841264362214, test loss = 1.2571718749674525\n",
            "Epoch 87: training loss = 0.3557356193066567, test loss = 0.3628745265214624\n",
            "Epoch 88: training loss = 0.3850186932177658, test loss = 0.38865278617874355\n",
            "Epoch 89: training loss = 0.3862492653234722, test loss = 0.3989825435286615\n",
            "Epoch 90: training loss = 0.33944628762871504, test loss = 0.3494009923477858\n",
            "Epoch 91: training loss = 0.4791123506081875, test loss = 0.48040015511970924\n",
            "Epoch 92: training loss = 0.40791808941941377, test loss = 0.4265054494137134\n",
            "Epoch 93: training loss = 0.3791105596145763, test loss = 0.38307975756716117\n",
            "Epoch 94: training loss = 0.35310274543486336, test loss = 0.36104098868327356\n",
            "Epoch 95: training loss = 0.4281995108171919, test loss = 0.4383646662691691\n",
            "Epoch 96: training loss = 0.4636008312258946, test loss = 0.4804915114436035\n",
            "Epoch 97: training loss = 0.3593293836049054, test loss = 0.36230180709289583\n",
            "Epoch 98: training loss = 0.5425061872037945, test loss = 0.5540986372295846\n",
            "Epoch 99: training loss = 0.47768701930265656, test loss = 0.49669250721135005\n",
            "Epoch 100: training loss = 0.40005460923573316, test loss = 0.40090813024092636\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxh2g1E0Agae",
        "colab_type": "text"
      },
      "source": [
        "##Model Evaluation using confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eUPN8K_567Q",
        "colab_type": "code",
        "outputId": "187bda0d-02cb-4443-f80c-cc8f458525da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "cache = feed_forward(X_test, params)\n",
        "predictions = np.argmax(cache[\"A2\"], axis=0)\n",
        "labels = np.argmax(Y_test, axis=0)\n",
        "\n",
        "print(classification_report(predictions, labels))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.86      0.91      1099\n",
            "           1       0.97      0.96      0.96      1152\n",
            "           2       0.94      0.78      0.85      1250\n",
            "           3       0.76      0.93      0.84       825\n",
            "           4       0.85      0.93      0.89       897\n",
            "           5       0.83      0.90      0.86       829\n",
            "           6       0.90      0.96      0.93       900\n",
            "           7       0.87      0.96      0.91       930\n",
            "           8       0.86      0.79      0.83      1066\n",
            "           9       0.89      0.85      0.87      1052\n",
            "\n",
            "    accuracy                           0.89     10000\n",
            "   macro avg       0.88      0.89      0.89     10000\n",
            "weighted avg       0.89      0.89      0.89     10000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: RuntimeWarning: overflow encountered in exp\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}